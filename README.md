# DS_Internship_Tochka_2026

Проект решает задачу предварительной фильтрации “грязных” веб-текстов перед использованием в претрейне LLM.

Мы обучаем 3 независимых бинарных классификатора по одному тексту `text`:

- **integrity** — связность/единство темы (статья vs список/шум)
- **factuality** — наличие фактологического содержания
- **truthfulness** — правдоподобие относительно common-sense знаний о реальном мире

Важно: в данных встречается метка **0.5** (“непонятно”). По постановке задачи такие примеры **не учитываются** в метрике и **игнорируются** при обучении.

---

## Данные

Архив содержит:

- `train.parquet` — обучение (колонки: `text`, `integrity`, `factuality`, `truthfulness` + `*_reasoning`)
- `test.parquet` — тест (колонка: `text`)
- `sample_submission.csv` — пример формата ответа

`uuid` находится **в индексе** датафреймов (index name = `uuid`).

---

## Метрика

Для каждого из 3 таргетов считается **F1-score** по примерам с метками {0, 1}.  
Примеры с истинной меткой **0.5** исключаются из подсчёта.  
Итоговая метрика = среднее арифметическое F1 по трём таргетам.

---

## Решение

Базовое решение сделано максимально простым и прозрачным:

- **TF-IDF** по **символьным n-граммам** (`char_wb`, 3–5) — хорошо ловит шаблонный web-шум (меню, списки, SEO-тексты)
- **Logistic Regression** (3 отдельные модели для 3 таргетов)
- **Игнор 0.5** в обучении (маска `y != 0.5`)
- **Подбор порога** для каждого таргета по валидации (важно при дисбалансе классов)

---

## Запуск (Google Colab)

1. Загрузите `train.parquet` и `test.parquet` в Google Drive.
2. Откройте ноутбук `train.ipynb` (или вставьте блоки из Colab-версии кода).
3. Укажите пути к файлам:
   ```python
   train_path = "/content/drive/MyDrive/.../train.parquet"
   test_path  = "/content/drive/MyDrive/.../test.parquet"

## Финальная метрика F1 в проетке = 0.9106
